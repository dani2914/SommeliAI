{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users\n"
     ]
    }
   ],
   "source": [
    "# Change directory to VSCode workspace root so that relative path loads work correctly. Turn this addition off with the DataScience.changeDirOnImportExport setting\n",
    "# ms-python.python added\n",
    "import os\n",
    "try:\n",
    "\tos.chdir(os.path.join(os.getcwd(), '../..'))\n",
    "\tprint(os.getcwd())\n",
    "except:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd ./sanjeevtewani/x/coursework/coms6998/SommeliAI/notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Why do we care?\n",
    " We're interested in exploring probabilistic programming as it\n",
    " applies to LDA and its variants.  LDA describes an extremely\n",
    " intuitive generative process, and because of this it enjoys\n",
    " continued research into its expansions. It is also both flexible\n",
    " and interpretable.  Since everybody here knows what LDA is, we\n",
    " won't go over the details.\n",
    "\n",
    " But, inference is really, really hard.  Most expansions to LDA that\n",
    " get published require subtle tricks to even get inference working.\n",
    "\n",
    " Examples are:\n",
    "   1. Supervised LDA for classification only works for real-valued supervision;\n",
    "      (Blei & McAuliffe, 2008)\n",
    "   2. Multiple Classification LDA was published a full year later; it required a\n",
    "      subtle application of Jensen's inequality to reduce O(K^N) time to O(K^2)\n",
    "      (Wang et al., 2009)\n",
    "   3. Hierarchical Supervised LDA (Perotte, 2011) can't model a true \n",
    "      is-a-this-and-not-that hierarchical relationship\n",
    " Just about every incremental idea requires some special trick, no matter how\n",
    " logical the idea is.\n",
    "\n",
    "__In spite of how understandable and flexible LDA__ is, even statisticians and\n",
    "practitioners will have a tough time deploying criticizable models for their needs.\n",
    "\n",
    "Fortunately, using Pyro to overcome intractable integrals was day 2; so let's get started\n",
    "with LDA in Pyro!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dataset and Course of Research\n",
    " We study almost 300,000 wine reviews from WineEnthusiast.com.  This dataset is\n",
    " richly tagged, with numerical scores from 0 to 100, hierarchical region information\n",
    " (country->region->winery) and variety.\n",
    " Reviews are short but basically already bags of words; we don't anticipate many words\n",
    " being wasted on nuanced semantics or stop words, so we believe that these reviews may\n",
    " be long enough for LDA to work.\n",
    " \n",
    " > \"Damp earth, black plum and dank forest herbs show\n",
    " > on the nose of this single-vineyard expression. The palate offers\n",
    " > cranberry and raspberry as well as savory soy and dried beef flavors,\n",
    " > all with earthy herbs in the background.\"\n",
    " \n",
    "As such, we expect to see a progression of topic modelling capabilities as we march\n",
    "down our list of models:\n",
    " - LDA,\n",
    " - LDA + classification v. supervised LDA,\n",
    " - Hierarchical LDA + classification v. supervised LDA\n",
    " - Hierarchical supervised LDA v. supervised LDA\n",
    " - Spectral Methods for supervised LDA v. supervised LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Vanilla LDA\n",
    " __Top Words Per Topic (10 topics)__\n",
    " - aroma,dry,black,tannin,drink,cherry,finish,fruit,wine,flavor\n",
    " - black,drink,acidity,palate,finish,tannin,cherry,fruit,wine,flavor\n",
    " - aroma,ripe,dry,tannin,acidity,finish,cherry,fruit,wine,flavor\n",
    " - acidity,dry,drink,tannin,aroma,finish,cherry,fruit,flavor,wine\n",
    " - drink,black,palate,acidity,tannin,finish,cherry,fruit,wine,flavor\n",
    " - acidity,drink,tannin,aroma,dry,cherry,finish,fruit,flavor,wine\n",
    " - aroma,acidity,palate,black,tannin,finish,cherry,fruit,wine,flavor\n",
    " - acidity,black,aroma,tannin,dry,cherry,finish,fruit,wine,flavor\n",
    " - drink,aroma,cherry,acidity,dry,tannin,finish,fruit,flavor,wine\n",
    " - aroma,dry,palate,acidity,tannin,cherry,finish,fruit,wine,flavor\n",
    "\n",
    "I'm not certain what iteration or hyperparameter was used for this run,\n",
    "but I can assure you we ran many, and the results were all the same.\n",
    "\n",
    "# Supervised LDA?\n",
    "Perhaps our data is truly just a very poor fit for LDA; this was always a risk.  We do expect that using more supervision, however, we can separate out meaningful topics for classification; if the objective of LDA\n",
    "may itself not offer enough rewards separate out topics, an extra loss may help.\n",
    "\n",
    "# sLDA's top words per topic\n",
    " - palate, style, structure, aromas, sweet, crisp, mouth, cherry, soft, spice\n",
    " - soft, citrus, cherry, crisp, palate, blackberry, apple, like, aromas, cabernet\n",
    " - aromas, cherry, spice, palate, chocolate, soft, cabernet, best, sweet, pinot\n",
    " - sweet, soft, cherry, palate, style, crisp, aromas, shows, mouth, plenty\n",
    " - cherry, soft, aromas, palate, touch, cedar, spice, sweet, made, plenty\n",
    " - cherry, palate, aromas, chocolate, merlot, crisp, plenty, fresh, pomegranate, sauvignon\n",
    " - sweet, cherries, shows, soft, aromas, palate, structure, cherry, cabernet, green\n",
    " - cherry, palate, like, spice, shows, sweet, soft, full, blend, green\n",
    " - palate, cherry, shows, aromas, cola, soft, cherries, raspberry, structure, crisp\n",
    " - cherry, palate, like, sweet, shows, citrus, polished, aromas, soft, cherries\n",
    " \n",
    "What's going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Collapse\n",
    "\n",
    "\n",
    "We want to scrutinize each parameter update from Pyro and CAVI to get a sense of what's going on.  Pyro employs BBVI for discrete distributions; it will furthermore use context clues from plates to Rao-Blackwellize where possible.  We hand derive the updates for the specific case of vanilla LDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Updates: Gamma\n",
    "BBVI:\n",
    "![](files/bbvi_update_gamma.png)\n",
    "![](files/bbvi_update_phi.png)\n",
    "\n",
    "Via Monte-Carlo (B samples from gamma)\n",
    "![](files/montecarlo_update_gamma.png)\n",
    "![](files/montecarlo_update_phi.png)\n",
    "\n",
    "And compared to CAVI\n",
    "![](files/cavi_update_gamma.png)\n",
    "![](files/cavi_update_phi.png)\n",
    "\n",
    "\n",
    "A few things to note:\n",
    " - updates in each aren't directly comparable; CAVI is run until convergence while BBVI will step iteratively (along with other parameters).  But the similarities are evident\n",
    " - All updates show some tradeoff between updating a parameter and shrinking toward its prior. \\theta isn't the prior of \\phi, but they are closely related via the model.\n",
    " - Both BBVI updates have Monte-Carlo estimates that can be written as KL divergences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How so?\n",
    "\n",
    "![](files/bbvi_kldiv_gamma.png)\n",
    "![](files/bbvi_kldiv_phi.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This term: log(p(z_{d,n}) / q(z_{d,n} \\vert \\phi_{d,n}), should trigger some alarm bells.  This term will guide our variational distribution towards the unconditional p(z).  This is a hallmark of posterior collapse.  Once the variational parameters are guided towards a collapsed maximum, the gradient updates will drag all model parameters towards the collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # CAVI for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # References\n",
    " (Blei & McAuliffe, 2008) https://papers.nips.cc/paper/3328-supervised-topic-models.pdf\n",
    " (Wang et al., 2009) http://vision.stanford.edu/pdf/WangBleiFei-Fei_CVPR2009.pdf\n",
    " (Schroeder, 2018) https://edoc.hu-berlin.de/bitstream/handle/18452/19516/thesis_schroeder_ken.pdf?sequence=3\n",
    " (Perotte et al., 2011) https://papers.nips.cc/paper/4313-hierarchically-supervised-latent-dirichlet-allocation\n",
    " (Thoutt, 2017) https://www.kaggle.com/zynicide/wine-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3.0
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
